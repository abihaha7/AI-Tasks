{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Introduction"},{"metadata":{},"cell_type":"markdown","source":"![](http://www.droid-life.com/wp-content/uploads/2019/08/imdb.jpg)"},{"metadata":{},"cell_type":"markdown","source":"Welcome to the notebook of IMDb dataset. IMDb stands for Internet movie database which is an online database of information related to films, television programs, home videos, video games and streaming content online owned by [Amazon](http://amazon.com). It is a dataset of 50,000 highly polarised reviews. They are split into 25,000 for training and 25,000 for testing, each set consisting of 50% negative and 50% positive reviews.\n\nIn this notebook, I am using Keras API, building model using CNN(Convolutional neural network), using layer embeddings with max pooling the layer. Finally I will be  evaluating the results.\n\n<font color=\"green\" size=4>Please do upvote the notebook if you liked it. It motivates me write more quality content:-)</font>"},{"metadata":{},"cell_type":"markdown","source":"# Acknowledgements\n\n1. [ggplot2 Docs - by CRAN](https://cran.r-project.org/web/packages/ggplot2/ggplot2.pdf)\n2. [ggplot2 R Tutorials - by tidyverse ](https://ggplot2.tidyverse.org/)\n3. [Keras Docs - by CRAN](https://cran.r-project.org/web/packages/keras/index.html)\n4. [Keras R Tutorial - by RStudio](https://keras.rstudio.com/)\n5. [Optimizers Docs & Tutoria - by Keras.io](https://keras.io/api/optimizers/)] \n6. [Losses Docs & Tutorials - by Keras.io](https://keras.io/api/losses/)"},{"metadata":{},"cell_type":"markdown","source":"# Contents\n\n* [<font size=4>Handling data and packages </font>](#1)\n    * [Loading data and packages](#1.1)\n    * [Structure of dataset](#1.2)\n    * [Data Cleaning](#1.3)\n    * [Splitting into train and test](#1.4)\n\n* [<font size=4>Length and Shapes of dataset</font>](#2)\n    * [Length of dataset](#2.1)\n    * [Paddling training data](#2.2)\n    * [Defining shapes of dataset](#2.3)\n\n* [<font size=4>Modeling</font>](#3)\n    * [Preparing the ground](#3.1)\n    * [Keras model](#3.2)\n    * [Model Compiling](#3.3)\n    * [Model Fitting](#3.4)\n    * [Model Evaluation](#3.5)\n\n\n* [<font size=4>Takeaways</font>](#4)\n\n\n* [<font size=4>Ending note</font>](#5)"},{"metadata":{},"cell_type":"markdown","source":"# Handling data and packages <a id=\"1\"></a>"},{"metadata":{},"cell_type":"markdown","source":"## Loading data and packages <a id=\"1.1\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Loading libraries\nlibrary(data.table)\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(caret)\nlibrary(keras)\n\n\n# Initializing variables\nmax_features <- 11000\nmax_len <- 500\n\n# Loading data\nimdb_data <- dataset_imdb(num_words = max_features)","execution_count":1,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Structure of dataset <a id=\"1.2\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"str(imdb_data)","execution_count":2,"outputs":[{"output_type":"stream","text":"List of 2\n $ train:List of 2\n  ..$ x:List of 25000\n  .. ..$ : int [1:218] 1 14 22 16 43 530 973 1622 1385 65 ...\n  .. ..$ : int [1:189] 1 194 1153 194 8255 78 228 5 6 1463 ...\n  .. ..$ : int [1:141] 1 14 47 8 30 31 7 4 249 108 ...\n  .. ..$ : int [1:550] 1 4 2 2 33 2804 4 2040 432 111 ...\n  .. ..$ : int [1:147] 1 249 1323 7 61 113 10 10 13 1637 ...\n  .. ..$ : int [1:43] 1 778 128 74 12 630 163 15 4 1766 ...\n  .. ..$ : int [1:123] 1 6740 365 1234 5 1156 354 11 14 5327 ...\n  .. ..$ : int [1:562] 1 4 2 716 4 65 7 4 689 4367 ...\n  .. ..$ : int [1:233] 1 43 188 46 5 566 264 51 6 530 ...\n  .. ..$ : int [1:130] 1 14 20 47 111 439 3445 19 12 15 ...\n  .. ..$ : int [1:450] 1 785 189 438 47 110 142 7 6 7475 ...\n  .. ..$ : int [1:99] 1 54 13 1610 14 20 13 69 55 364 ...\n  .. ..$ : int [1:117] 1 13 119 954 189 1554 13 92 459 48 ...\n  .. ..$ : int [1:238] 1 259 37 100 169 1653 1107 11 14 418 ...\n  .. ..$ : int [1:109] 1 503 20 33 118 481 302 26 184 52 ...\n  .. ..$ : int [1:129] 1 6 964 437 7 58 43 1402 11 6 ...\n  .. ..$ : int [1:163] 1 7092 1662 11 4 1749 9 4 2165 4 ...\n  .. ..$ : int [1:752] 1 33 4 5673 7 4 2 194 2 3089 ...\n  .. ..$ : int [1:212] 1 13 28 64 69 4 8742 7 319 14 ...\n  .. ..$ : int [1:177] 1 3432 26 9 6 1220 731 939 44 6 ...\n  .. ..$ : int [1:129] 1 617 11 3875 17 2 14 966 78 20 ...\n  .. ..$ : int [1:140] 1 466 49 2036 204 2442 40 4 6724 732 ...\n  .. ..$ : int [1:256] 1 13 784 886 857 15 135 142 40 2 ...\n  .. ..$ : int [1:888] 1 4 712 19 2 2 2 963 2 26 ...\n  .. ..$ : int [1:93] 1 4 204 7610 20 16 93 11 9075 19 ...\n  .. ..$ : int [1:142] 1 14 9 6 55 641 2854 212 44 6 ...\n  .. ..$ : int [1:220] 1 4 288 310 3202 7 241 672 4 2 ...\n  .. ..$ : int [1:193] 1 75 69 8 140 8 35 2 38 75 ...\n  .. ..$ : int [1:171] 1 4679 2784 1482 11 450 7 134 364 352 ...\n  .. ..$ : int [1:221] 1 13 28 332 4 274 6 378 7 211 ...\n  .. ..$ : int [1:174] 1 13 1059 14 33 6 2181 2824 32 13 ...\n  .. ..$ : int [1:647] 1 6 565 255 5964 875 103 196 167 10614 ...\n  .. ..$ : int [1:233] 1 4 86 390 1241 520 6 52 1384 51 ...\n  .. ..$ : int [1:162] 1 13 92 124 51 12 9 13 169 38 ...\n  .. ..$ : int [1:597] 1 111 28 3431 15 2 475 455 4127 9 ...\n  .. ..$ : int [1:234] 1 1255 1223 5547 1265 2390 1747 8 4 268 ...\n  .. ..$ : int [1:51] 1 806 13 43 161 169 4 875 551 17 ...\n  .. ..$ : int [1:336] 1 23 3333 7449 7505 4 254 157 2 7 ...\n  .. ..$ : int [1:139] 1 17 19 111 85 1719 1181 3135 201 14 ...\n  .. ..$ : int [1:231] 1 14 38 446 1034 9 394 13 435 8 ...\n  .. ..$ : int [1:704] 1 14 16 4 840 5582 20 5 4 236 ...\n  .. ..$ : int [1:142] 1 14 22 16 23 522 33 314 54 13 ...\n  .. ..$ : int [1:861] 1 1710 14 733 1367 1028 81 24 332 48 ...\n  .. ..$ : int [1:132] 1 4 229 18 14 248 1844 1422 9 38 ...\n  .. ..$ : int [1:122] 1 3420 9 34 230 61 514 7 32 7 ...\n  .. ..$ : int [1:570] 1 11 14 4419 3073 14 9061 50 26 1093 ...\n  .. ..$ : int [1:55] 1 568 65 9 4689 31 7 4 118 495 ...\n  .. ..$ : int [1:214] 1 806 21 13 80 2372 199 4 114 347 ...\n  .. ..$ : int [1:103] 1 54 7850 5397 8633 7455 9 2090 2 23 ...\n  .. ..$ : int [1:186] 1 13 244 1713 1681 8 97 134 243 7 ...\n  .. ..$ : int [1:113] 1 13 165 219 14 20 33 6 750 17 ...\n  .. ..$ : int [1:169] 1 159 13 296 14 22 13 332 6 733 ...\n  .. ..$ : int [1:469] 1 14 364 1242 2460 2 47 43 77 7548 ...\n  .. ..$ : int [1:138] 1 1400 168 855 19 12 50 26 76 128 ...\n  .. ..$ : int [1:302] 1 101 20 11 63 7564 2 46 1421 6 ...\n  .. ..$ : int [1:766] 1 5011 892 711 12 2774 38 2428 145 11 ...\n  .. ..$ : int [1:351] 1 1318 13 191 264 146 4 86 5 64 ...\n  .. ..$ : int [1:146] 1 13 974 13 69 8 702 930 143 14 ...\n  .. ..$ : int [1:59] 1 13 296 4 20 11 6 4435 5 13 ...\n  .. ..$ : int [1:206] 1 209 888 14 22 47 8 30 31 7 ...\n  .. ..$ : int [1:107] 1 13 219 14 33 4 2 22 1413 12 ...\n  .. ..$ : int [1:152] 1 591 92 851 42 60 104 44 2644 14 ...\n  .. ..$ : int [1:186] 1 13 258 14 20 8 30 6 87 326 ...\n  .. ..$ : int [1:431] 1 4 2019 9 149 16 35 221 22 585 ...\n  .. ..$ : int [1:147] 1 146 242 31 7 4 1126 2406 2266 451 ...\n  .. ..$ : int [1:684] 1 1810 8 516 7732 93 6 227 7 6 ...\n  .. ..$ : int [1:383] 1 1028 11 86 8213 14 1327 1210 1124 5205 ...\n  .. ..$ : int [1:324] 1 2 8810 322 7398 5 68 1667 476 2 ...\n  .. ..$ : int [1:252] 1 13 286 1017 76 5 8 30 1202 13 ...\n  .. ..$ : int [1:263] 1 48 335 6 337 7 22 1359 5 104 ...\n  .. ..$ : int [1:787] 1 6 1380 6733 3453 54 49 432 7 5682 ...\n  .. ..$ : int [1:211] 1 14 20 218 290 4 22 12 16 3551 ...\n  .. ..$ : int [1:314] 1 49 24 38 2 1028 1404 10 10 138 ...\n  .. ..$ : int [1:118] 1 480 302 18 6 20 7 14 58 6 ...\n  .. ..$ : int [1:390] 1 670 5304 1616 97 6 20 40 14 21 ...\n  .. ..$ : int [1:132] 1 1756 5663 9 2990 2 133 177 17 6 ...\n  .. ..$ : int [1:710] 1 1065 2474 7 3508 2 645 113 17 6 ...\n  .. ..$ : int [1:306] 1 17 210 14 9 35 6213 431 7 4 ...\n  .. ..$ : int [1:167] 1 2500 1040 4 327 1208 44 14 215 28 ...\n  .. ..$ : int [1:115] 1 11 4 402 3469 111 7 178 37 69 ...\n  .. ..$ : int [1:95] 1 435 8 67 14 17 72 5 61 761 ...\n  .. ..$ : int [1:158] 1 31 7 61 118 369 839 14 20 120 ...\n  .. ..$ : int [1:156] 1 66 371 2 2 373 21 284 2 2567 ...\n  .. ..$ : int [1:82] 1 4 1126 282 13 69 8 67 14 20 ...\n  .. ..$ : int [1:502] 1 14 22 7930 236 314 33 2 5510 750 ...\n  .. ..$ : int [1:314] 1 13 144 1260 138 13 520 14 418 7 ...\n  .. ..$ : int [1:190] 1 13 92 400 140 46 7 61 96 8 ...\n  .. ..$ : int [1:174] 1 61 795 203 30 6 227 7 6 1361 ...\n  .. ..$ : int [1:60] 1 18 6 20 19 6 114 40 14 13 ...\n  .. ..$ : int [1:145] 1 13 219 14 22 5236 145 137 780 23 ...\n  .. ..$ : int [1:214] 1 11 192 5192 2 125 2139 1253 7 2 ...\n  .. ..$ : int [1:659] 1 541 5156 517 19 4 4791 7 2408 827 ...\n  .. ..$ : int [1:408] 1 474 66 66 473 8 67 14 20 5 ...\n  .. ..$ : int [1:515] 1 7931 4 425 410 2568 4 876 7 4 ...\n  .. ..$ : int [1:461] 1 121 81 13 895 13 473 8 358 14 ...\n  .. ..$ : int [1:202] 1 13 66 215 28 1059 6 275 22 39 ...\n  .. ..$ : int [1:238] 1 827 2 2 10 10 1251 8598 300 2 ...\n  .. ..$ : int [1:170] 1 24 15 76 183 593 11 14 20 21 ...\n  .. ..$ : int [1:107] 1 14 20 9 389 10 10 13 16 2 ...\n  .. .. [list output truncated]\n  ..$ y: int [1:25000] 1 0 0 1 0 0 1 0 1 0 ...\n $ test :List of 2\n  ..$ x:List of 25000\n  .. ..$ : int [1:68] 1 591 202 14 31 6 717 10 10 2 ...\n  .. ..$ : int [1:260] 1 14 22 3443 6 176 7 5063 88 12 ...\n  .. ..$ : int [1:603] 1 111 748 4368 1133 2 2 4 87 1551 ...\n  .. ..$ : int [1:181] 1 13 1228 119 14 552 7 20 190 14 ...\n  .. ..$ : int [1:108] 1 40 49 85 84 1040 146 6 783 254 ...\n  .. ..$ : int [1:132] 1 146 427 5718 14 20 218 112 2962 32 ...\n  .. ..$ : int [1:761] 1 1822 424 8 30 43 6 173 7 6 ...\n  .. ..$ : int [1:180] 1 4 2 745 2 912 9 2 8 2 ...\n  .. ..$ : int [1:134] 1 363 69 6 196 119 1586 19 6514 2 ...\n  .. ..$ : int [1:370] 1 14 22 9 121 4 1354 3135 3882 8 ...\n  .. ..$ : int [1:209] 1 1581 34 7908 5082 23 6 1374 1120 7 ...\n  .. ..$ : int [1:248] 1 54 13 86 219 14 20 11 4 750 ...\n  .. ..$ : int [1:398] 1 449 3214 449 3214 12 66 214 23 61 ...\n  .. ..$ : int [1:326] 1 13 645 149 14 88 13 197 12 16 ...\n  .. ..$ : int [1:131] 1 6 1301 664 15 1457 6 406 393 23 ...\n  .. ..$ : int [1:255] 1 387 72 86 380 46 34 660 300 46 ...\n  .. ..$ : int [1:127] 1 39 4142 86 13 296 14 20 13 235 ...\n  .. ..$ : int [1:184] 1 1659 2 3717 9 6 2343 37 456 18 ...\n  .. ..$ : int [1:188] 1 13 16 66 2 56 8 106 54 107 ...\n  .. ..$ : int [1:105] 1 208 38 25 28 6 10781 3400 7 1093 ...\n  .. ..$ : int [1:230] 1 14 22 16 31 15 13 28 4465 8 ...\n  .. ..$ : int [1:137] 1 14 9 31 7 61 1640 910 108 12 ...\n  .. ..$ : int [1:88] 1 89 1319 8 798 692 1287 6 736 6 ...\n  .. ..$ : int [1:70] 1 2127 1256 8 1686 39 109 8 109 11 ...\n  .. ..$ : int [1:170] 1 2 8415 5968 2102 2 39 4819 11 5399 ...\n  .. ..$ : int [1:305] 1 146 24 252 138 14 22 9 2 38 ...\n  .. ..$ : int [1:273] 1 13 69 332 4692 857 2 14 3720 5675 ...\n  .. ..$ : int [1:134] 1 3799 117 183 16 6 66 52 20 13 ...\n  .. ..$ : int [1:232] 1 688 8 6 55 5328 4593 5653 13 219 ...\n  .. ..$ : int [1:264] 1 4 145 7 4 288 18 14 20 2 ...\n  .. ..$ : int [1:99] 1 1756 5663 122 6 4796 292 940 14 22 ...\n  .. ..$ : int [1:133] 1 48 25 535 15 14 20 9 368 7 ...\n  .. ..$ : int [1:121] 1 48 25 28 115 332 4 356 1067 1219 ...\n  .. ..$ : int [1:521] 1 48 14 9 24 2699 2561 23 175 1029 ...\n  .. ..$ : int [1:133] 1 1018 3577 4150 3188 2 8 30 35 2 ...\n  .. ..$ : int [1:124] 1 14 9 44 31 7 4 249 102 474 ...\n  .. ..$ : int [1:228] 1 14 20 9 434 31 7 4 833 108 ...\n  .. ..$ : int [1:159] 1 2 2688 17 644 961 46 160 480 65 ...\n  .. ..$ : int [1:132] 1 449 558 12 100 30 6 55 221 22 ...\n  .. ..$ : int [1:141] 1 14 664 16 357 5 179 379 10 10 ...\n  .. ..$ : int [1:310] 1 11 2 6 185 132 584 11 6 686 ...\n  .. ..$ : int [1:431] 1 117 2 738 8 2223 9 160 11 4 ...\n  .. ..$ : int [1:214] 1 260 77 6 4279 337 18 111 153 6662 ...\n  .. ..$ : int [1:185] 1 13 219 14 5126 20 88 13 244 6 ...\n  .. ..$ : int [1:549] 1 2285 1447 2435 2 2365 2018 18 692 19 ...\n  .. ..$ : int [1:136] 1 4 752 7486 16 398 34 72 54 13 ...\n  .. ..$ : int [1:89] 1 23 2195 6 513 9 2 34 6 7472 ...\n  .. ..$ : int [1:298] 1 313 7 4 6333 82 573 17 2 9 ...\n  .. ..$ : int [1:127] 1 402 10286 792 448 23 6 1063 868 297 ...\n  .. ..$ : int [1:252] 1 13 191 391 138 899 6320 62 967 14 ...\n  .. ..$ : int [1:289] 1 86 7 13 144 213 46 15 13 343 ...\n  .. ..$ : int [1:125] 1 13 43 332 35 1727 196 733 23 4 ...\n  .. ..$ : int [1:64] 1 13 69 210 473 8 67 14 22 5 ...\n  .. ..$ : int [1:111] 1 1469 2102 5 2163 26 6 378 7 4 ...\n  .. ..$ : int [1:132] 1 12 299 40 129 644 1667 311 830 6 ...\n  .. ..$ : int [1:256] 1 14 9 6 318 22 48 25 124 4 ...\n  .. ..$ : int [1:100] 1 13 16 55 685 54 14 123 16 6769 ...\n  .. ..$ : int [1:152] 1 48 25 447 4 5040 2475 920 1219 6537 ...\n  .. ..$ : int [1:203] 1 11 4618 689 2 2 34 2643 745 2 ...\n  .. ..$ : int [1:124] 1 449 89 4916 14 20 9 13 92 124 ...\n  .. ..$ : int [1:113] 1 13 66 423 4 20 1065 162 2 21 ...\n  .. ..$ : int [1:208] 1 4 969 80 168 55 1081 8 25 38 ...\n  .. ..$ : int [1:106] 1 43 191 106 14 227 99 111 211 45 ...\n  .. ..$ : int [1:234] 1 66 133 4 785 438 1936 741 1324 5 ...\n  .. ..$ : int [1:114] 1 146 770 8 332 32 4 1123 795 23 ...\n  .. ..$ : int [1:210] 1 1318 45 77 6 196 58 237 207 236 ...\n  .. ..$ : int [1:733] 1 14 20 93 72 104 7 89 13 100 ...\n  .. ..$ : int [1:173] 1 61 336 4 632 9 1047 163 5 1036 ...\n  .. ..$ : int [1:321] 1 39 4 86 8 4 236 136 7 4 ...\n  .. ..$ : int [1:86] 1 14 20 203 2 977 8 30 2 5 ...\n  .. ..$ : int [1:112] 1 1318 13 447 14 20 14 22 16 1061 ...\n  .. ..$ : int [1:195] 1 14 22 188 329 692 74 2756 7 68 ...\n  .. ..$ : int [1:101] 1 2676 9 4 243 7 20 36 93 11 ...\n  .. ..$ : int [1:194] 1 14 20 9 24 290 4 58 12 304 ...\n  .. ..$ : int [1:122] 1 14 20 16 608 17 230 17 102 140 ...\n  .. ..$ : int [1:324] 1 4 2474 7 2 47 8 30 31 7 ...\n  .. ..$ : int [1:195] 1 13 1053 4480 234 7 61 113 23 14 ...\n  .. ..$ : int [1:257] 1 50 28 77 55 171 87 212 108 11 ...\n  .. ..$ : int [1:307] 1 50 186 8 30 6 9557 7 438 23 ...\n  .. ..$ : int [1:78] 1 14 20 47 188 8 30 4 433 20 ...\n  .. ..$ : int [1:157] 1 19 4 578 1401 7 6799 3236 14 16 ...\n  .. ..$ : int [1:213] 1 2 4 248 20 2 6 55 2509 5 ...\n  .. ..$ : int [1:163] 1 33 2405 197 4 1120 7 14 123 468 ...\n  .. ..$ : int [1:122] 1 146 24 83 635 287 15 76 21 14 ...\n  .. ..$ : int [1:197] 1 10 10 132 13 43 2488 264 14 20 ...\n  .. ..$ : int [1:169] 1 13 122 6 733 18 14 2030 2615 9730 ...\n  .. ..$ : int [1:81] 1 73 474 28 8 135 15 13 81 205 ...\n  .. ..$ : int [1:242] 1 13 191 79 14 509 125 61 1224 45 ...\n  .. ..$ : int [1:218] 1 13 188 5158 8 14 2446 31 2 2655 ...\n  .. ..$ : int [1:193] 1 864 13 124 198 1591 623 23 94 2558 ...\n  .. ..$ : int [1:467] 1 1318 133 9 160 87 8894 20 198 33 ...\n  .. ..$ : int [1:74] 1 13 104 14 9 6 87 356 969 22 ...\n  .. ..$ : int [1:76] 1 114 600 229 6 3592 7 6363 116 24 ...\n  .. ..$ : int [1:736] 1 4 3768 356 20 1308 47 1084 4 3241 ...\n  .. ..$ : int [1:448] 1 2 6172 526 34 4 530 2 5893 2 ...\n  .. ..$ : int [1:200] 1 14 9 6 1332 1253 7 4 592 848 ...\n  .. ..$ : int [1:185] 1 13 296 14 20 260 115 332 4 274 ...\n  .. ..$ : int [1:124] 1 2787 7056 59 93 14 20 18 72 207 ...\n  .. ..$ : int [1:122] 1 216 23 150 89 122 32 7 134 1020 ...\n  .. .. [list output truncated]\n  ..$ y: int [1:25000] 0 1 1 0 1 1 1 0 0 1 ...\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## Data Cleaning <a id=\"1.3\"></a>"},{"metadata":{},"cell_type":"markdown","source":"The IMDb dataset comes pre-installed in Keras library. So, the dataset of free of all missing values and data is already cleaned.:)"},{"metadata":{},"cell_type":"markdown","source":"## Splitting into train and test <a id=\"1.4\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"c(c(a_train, b_train), c(a_test, b_test)) %<-% imdb_data","execution_count":3,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Length and Shapes of dataset <a id=\"2\"></a>"},{"metadata":{},"cell_type":"markdown","source":"## Length of dataset <a id=\"2.1\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"cat(length(a_train), \"Sequences of train dataset\", \"\\n\")\ncat(length(a_test), \"Sequences of test dataset\")","execution_count":4,"outputs":[{"output_type":"stream","text":"25000 Sequences of train dataset \n25000 Sequences of test dataset","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## Padding training data <a id=\"2.2\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"a_train <- pad_sequences(a_train, maxlen = max_len)\na_test <- pad_sequences(a_test, maxlen = max_len)","execution_count":5,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Defining shapes of dataset <a id=\"2.2\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"cat(\"Shape of a_train:\", dim(a_train),\"\\n\")\ncat(\"Shape of a_test:\", dim(a_test), \"\\n\")","execution_count":6,"outputs":[{"output_type":"stream","text":"Shape of a_train: 25000 500 \nShape of a_test: 25000 500 \n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"The shapes of train dataset and test dataset are 25000x500 ."},{"metadata":{},"cell_type":"markdown","source":"# Modelling <a id=\"3\"></a>"},{"metadata":{},"cell_type":"markdown","source":"## Preparing the ground <a id=\"3.1\"></a>"},{"metadata":{},"cell_type":"markdown","source":"### Convolutional Neural Network(CNN)"},{"metadata":{},"cell_type":"markdown","source":"A **Convolutional Neural Network (ConvNet/CNN)** is a Deep Learning algorithm which can take in an input image, assign importance (learnable weights and biases) to various aspects/objects in the image and be able to differentiate one from the other. The pre-processing required in a ConvNet is much lower as compared to other classification algorithms. While in primitive methods filters are hand-engineered, with enough training, ConvNets have the ability to learn these filters/characteristics."},{"metadata":{},"cell_type":"markdown","source":"![](https://www.researchgate.net/publication/336805909/figure/fig1/AS:817888827023360@1572011300751/Schematic-diagram-of-a-basic-convolutional-neural-network-CNN-architecture-26.ppm)"},{"metadata":{},"cell_type":"markdown","source":"The **architecture of a ConvNet** is analogous to connectivity pattern of Neurons in the Human Brain and was inspired by the organization of the Visual Cortex. Individual neurons respond to stimuli only in a restricted region of the visual field known as the Receptive Field. A collection of such fields overlap to cover the entire visual area."},{"metadata":{},"cell_type":"markdown","source":"The **objective of the Convolution Operation** is to extract the high-level features such as edges, from the input image. ConvNets need not be limited to only one Convolutional Layer."},{"metadata":{},"cell_type":"markdown","source":"![](http://miro.medium.com/max/395/1*1VJDP6qDY9-ExTuQVEOlVg.gif)"},{"metadata":{},"cell_type":"markdown","source":"Conventionally, the first ConvLayer is responsible for capturing the Low-Level features such as edges, color, gradient orientation, etc. With added layers, the architecture adapts to the High-Level features as well, giving us a network which has the wholesome understanding of images in the dataset, similar to how we would.\nThere are two types of results to the operation â€” one in which the convolved feature is reduced in dimensionality as compared to the input, and the other in which the dimensionality is either increased or remains the same. This is done by applying Valid Padding in case of the former, or Same Padding in the case of the latter.\n\n\n\nFor more information, Please [Refer](https://cs231n.github.io/convolutional-networks/)"},{"metadata":{},"cell_type":"markdown","source":"### Word Embeddings"},{"metadata":{},"cell_type":"markdown","source":"**Word embeddings** are a family of natural language processing techniques aiming at mapping semantic meaning into a geometric space. This is done by associating a numeric vector to every word in a dictionary, such that the distance (e.g. L2 distance or more commonly cosine distance) between any two vectors would capture part of the semantic relationship between the two associated words. The geometric space formed by these vectors is called an embedding space.\n\nIn a good embeddings space, the \"path\" (a vector) to go from \"kitchen\" and \"dinner\" would capture precisely the semantic relationship between these two concepts. In this case the relationship is \"where x occurs\", so you would expect the vector kitchen - dinner (difference of the two embedding vectors, i.e. path to go from dinner to kitchen) to capture this \"where x occurs\" relationship. Basically, we should have the vectorial identity: dinner + (where x occurs) = kitchen (at least approximately). If that's indeed the case, then we can use such a relationship vector to answer questions. For instance, starting from a new vector, e.g. \"work\", and applying this relationship vector, we should get sometime meaningful, e.g. work + (where x occurs) = office, answering \"where does work occur?\".\n\n![](https://media.geeksforgeeks.org/wp-content/uploads/20200805214427/fgf1.png)\n\nFor instance, \"coconut\" and \"polar bear\" are words that are semantically quite different, so a reasonable embedding space would represent them as vectors that would be very far apart. But \"kitchen\" and \"dinner\" are related words, so they should be embedded close to each other. Word embeddings are computed by applying dimensionality reduction techniques to datasets of co-occurence statistics between words in a corpus of text. This can be done via neural networks (the \"word2vec\" technique), or via matrix factorization.\n\nWays to obtain word embeddings:\n\n1)Learn word embeddings jointly with the main task(e.g. document classification or sentiment prediction). In this setup, you would start with random word vectors, then learn your word vectors in the same way that you learn the weights of a neural network.\n\n2)Using **pre-trained word embeddings** i.e loading into your model word embeddings that were pre-computed using a different machine learning task than the one you are trying to solve\n\nFor more information, please [Refer](https://jjallaire.github.io/deep-learning-with-r-notebooks/notebooks/6.1-using-word-embeddings.nb.html)"},{"metadata":{},"cell_type":"markdown","source":"## Keras Model <a id=\"3.2\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"model_net <- keras_model_sequential() %>%\n  layer_embedding(input_dim = max_features, output_dim = 128,\n                  input_length = max_len) %>%\n  layer_conv_1d(filters = 32, kernel_size = 7, activation = \"relu\") %>%\n  layer_max_pooling_1d(pool_size = 5) %>%\n  layer_conv_1d(filters = 32, kernel_size = 7, activation = \"relu\") %>%\n  layer_global_max_pooling_1d() %>%\n  layer_dense(units = 1)\n\nsummary(model_net)","execution_count":7,"outputs":[{"output_type":"stream","text":"Model: \"sequential\"\n________________________________________________________________________________\nLayer (type)                        Output Shape                    Param #     \n================================================================================\nembedding (Embedding)               (None, 500, 128)                1408000     \n________________________________________________________________________________\nconv1d (Conv1D)                     (None, 494, 32)                 28704       \n________________________________________________________________________________\nmax_pooling1d (MaxPooling1D)        (None, 98, 32)                  0           \n________________________________________________________________________________\nconv1d_1 (Conv1D)                   (None, 92, 32)                  7200        \n________________________________________________________________________________\nglobal_max_pooling1d (GlobalMaxPool (None, 32)                      0           \n________________________________________________________________________________\ndense (Dense)                       (None, 1)                       33          \n================================================================================\nTotal params: 1,443,937\nTrainable params: 1,443,937\nNon-trainable params: 0\n________________________________________________________________________________\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## Model Compiling <a id=\"3.4\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Compiling step\nmodel_net %>% compile(\n  optimizer = optimizer_rmsprop(lr = 1e-4),\n  loss = \"binary_crossentropy\",\n  metrics = c(\"accuracy\")\n)","execution_count":8,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model Fitting <a id=\"3.5\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fitting \nmodel_net %>% fit(\n  a_train, b_train, \n  epochs = 10, \n  batch_size = 128,\n  validation_split = 0.2\n  )","execution_count":9,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model Evaluation <a id=\"3.6\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"metrics <- model_net %>% evaluate(a_test, b_test)\nmetrics","execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/html":"<dl>\n\t<dt>$loss</dt>\n\t\t<dd>0.472513861083984</dd>\n\t<dt>$accuracy</dt>\n\t\t<dd>0.863399982452393</dd>\n</dl>\n","text/markdown":"$loss\n:   0.472513861083984\n$accuracy\n:   0.863399982452393\n\n\n","text/latex":"\\begin{description}\n\\item[\\$loss] 0.472513861083984\n\\item[\\$accuracy] 0.863399982452393\n\\end{description}\n","text/plain":"$loss\n[1] 0.4725139\n\n$accuracy\n[1] 0.8634\n"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"# Takeaways  <a id=\"4\"></a>"},{"metadata":{},"cell_type":"markdown","source":"1. Building models using Keras API of a deep neural networks(DNN).\n2. Scoring higher accuracy rate using layer embeddings & max pooling layer in dense neural network.\n3. Model evaluation and fitting with proper hyperparameters."},{"metadata":{},"cell_type":"markdown","source":"## Ending Notes <a id=\"5\"></a>"},{"metadata":{},"cell_type":"markdown","source":"The model achieved the accuracy of 86.33% in model evaluation."},{"metadata":{},"cell_type":"markdown","source":"<font color=\"green\" size=4>This concludes the notebook. Please upvote to motivate me write more quality content :-)</font>"}],"metadata":{"kernelspec":{"name":"ir","display_name":"R","language":"R"},"language_info":{"name":"R","codemirror_mode":"r","pygments_lexer":"r","mimetype":"text/x-r-source","file_extension":".r","version":"3.6.3"}},"nbformat":4,"nbformat_minor":4}